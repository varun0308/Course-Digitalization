{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio_cot.wav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Audio extraction successful!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "# Define the input video file and output audio file\n",
    "mp4_file = \"Ses 03.mp4\"\n",
    "wav_file = \"audio_cot.wav\"\n",
    "\n",
    "# Load the video clip\n",
    "video_clip = VideoFileClip(mp4_file)\n",
    "\n",
    "# Extract the audio from the video clip\n",
    "audio_clip = video_clip.audio\n",
    "\n",
    "# Write the audio to a separate file\n",
    "audio_clip.write_audiofile(wav_file)\n",
    "\n",
    "# Close the video and audio clips\n",
    "audio_clip.close()\n",
    "video_clip.close()\n",
    "\n",
    "print(\"Audio extraction successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This example requires environment variables named \"SPEECH_KEY\" and \"SPEECH_REGION\"\n",
    "speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('AZURE_SUBSCRIPTION_KEY'), region=os.environ.get('AZURE_SERVICE_REGION'))\n",
    "audio_config = speechsdk.AudioConfig(filename=\"audio_cot.wav\")\n",
    "speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stop_cb(evt):\n",
    "    speech_recognizer.stop_continuous_recognition()\n",
    "    stop_cb(evt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_results = []\n",
    "\n",
    "def handle_final_result(evt):\n",
    "    all_results.append(evt.result.text)\n",
    "speech_recognizer.recognized.connect(handle_final_result)\n",
    "speech_recognizer.session_stopped.connect(stop_cb)\n",
    "speech_recognizer.canceled.connect(stop_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_recognizer.start_continuous_recognition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = \" \".join(all_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcription.txt\", \"w\") as fp:\n",
    "    fp.write(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"For a given transcription from a video to be published online, give a very short pre-read for the viewers on what to expect from the video\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\nPREREAD:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this video, we explore the concept of \"chain of thought\" prompting in language models, focusing on its importance for multi-step reasoning tasks. You\\'ll learn how traditional prompting methods can fall short when complex reasoning is required, and how the chain of thought technique can help induce logical thinking in language models. We\\'ll discuss the method\\'s implementation, including examples that illustrate how to structure prompts effectively to improve the accuracy of model responses. Join us as we unpack this influential prompting technique and its applications in enhancing language model performance!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"For a given transcription from the video published online, give a summary of the video for the viewers\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\SUMMARY:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this video, the speaker discusses the concept of \"chain of thought prompting\" as a technique to enhance the performance of language models, particularly in tasks that require multi-step reasoning. They explain that while traditional few-shot prompting may work for straightforward queries, it often falls short when complex reasoning is needed. The key idea is to encourage models to articulate their thought processes step-by-step rather than jumping directly to answers.\\n\\nThe speaker highlights the importance of structuring prompts in a way that illustrates the reasoning process, thereby enabling the model to generate more accurate responses. By providing detailed examples that break down the problem into intermediate steps, the model can learn to mimic this logical thinking in its future outputs.\\n\\nThe video emphasizes that this approach not only improves the accuracy of answers but also enhances interpretability, allowing users to understand the reasoning behind the model\\'s conclusions. The speaker encourages viewers to adopt this technique for tasks involving complex reasoning, particularly in math problems, and suggests that chain of thought prompting is a foundational method that many subsequent techniques will build upon.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert teacher in AI. For a given transcription from a video, generate 10 multiple choice questions that cover the topics discussed in this session. The questions are to be of recall-from-content type\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\QUESTIONS:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the main problem with few-shot prompting when it comes to multi-step reasoning?\n",
      "   - A) It generates too many answers\n",
      "   - B) It does not effectively guide the model through the necessary reasoning steps\n",
      "   - C) It requires too much data\n",
      "   - D) It is not applicable to language models\n",
      "   \n",
      "2. What is the key idea behind the chain of thought prompting method?\n",
      "   - A) To provide straightforward answers without reasoning\n",
      "   - B) To induce logical, step-by-step thinking in the model\n",
      "   - C) To simplify the input questions\n",
      "   - D) To minimize the number of examples used in prompting\n",
      "\n",
      "3. How does a language model like LLM generate tokens?\n",
      "   - A) By implementing logical reasoning\n",
      "   - B) Based on a series of previous tokens and their probabilities\n",
      "   - C) Through external computational tools\n",
      "   - D) By guessing the answers\n",
      "\n",
      "4. What does the implementation of chain of thought prompting aim to achieve?\n",
      "   - A) Generate random outputs\n",
      "   - B) Enable language models to generate a series of logical steps before arriving at an answer\n",
      "   - C) Eliminate the need for examples\n",
      "   - D) Increase the complexity of the model's architecture\n",
      "\n",
      "5. According to the transcription, what is a significant advantage of using chain of thought prompting?\n",
      "   - A) It reduces computation time\n",
      "   - B) It allows complex problems to be broken down into intermediate steps\n",
      "   - C) It avoids the use of examples altogether\n",
      "   - D) It results in faster training of language models\n",
      "\n",
      "6. In the example provided in the transcription, what was the result of using a standard prompting technique?\n",
      "   - A) The answer generated was correct\n",
      "   - B) The answer generated was wrong\n",
      "   - C) No answer was generated\n",
      "   - D) The model did not understand the question\n",
      "\n",
      "7. How can detailed prompts improve the performance of language models?\n",
      "   - A) By providing straightforward answers\n",
      "   - B) By encouraging the model to follow specific reasoning patterns\n",
      "   - C) By simplifying the input data\n",
      "   - D) By reducing the number of examples needed\n",
      "\n",
      "8. Which type of problems is chain of thought prompting particularly useful for?\n",
      "   - A) Simple factual queries\n",
      "   - B) Math problems or reasoning tasks that require multiple steps\n",
      "   - C) Creative writing tasks\n",
      "   - D) Image recognition tasks\n",
      "\n",
      "9. What type of information does the model focus on when using chain of thought prompting?\n",
      "   - A) The final answer alone\n",
      "   - B) The reasoning process and intermediate steps involved in reaching the answer\n",
      "   - C) The length of the input question\n",
      "   - D) The number of examples provided\n",
      "\n",
      "10. What does the presenter suggest about the model's ability to learn from examples?\n",
      "    - A) It cannot learn from examples at all\n",
      "    - B) It can mimic the process of thinking from given examples\n",
      "    - C) It only learns from incorrect examples\n",
      "    - D) It relies solely on its initial training data without learning from new examples\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manual-script-videos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
