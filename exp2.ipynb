{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "from utils import save_wav_from_mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_transcription_from_video(mp4_file, audio_file=None):\n",
    "    \n",
    "    if not audio_file:\n",
    "        audio_file = save_wav_from_mp4(mp4_file=mp4_file)\n",
    "        speech_config = speechsdk.SpeechConfig(subscription=os.environ.get('AZURE_SUBSCRIPTION_KEY'), region=os.environ.get('AZURE_SERVICE_REGION'))\n",
    "        audio_config = speechsdk.AudioConfig(filename=audio_file)\n",
    "    else:\n",
    "        audio_config = speechsdk.AudioConfig(filename=audio_file)\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "    \n",
    "    def stop_cb(evt):\n",
    "        speech_recognizer.stop_continuous_recognition()\n",
    "        stop_cb(evt)\n",
    "    def handle_final_result(evt):\n",
    "        all_results.append(evt.result.text)\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    speech_recognizer.recognized.connect(handle_final_result)\n",
    "    speech_recognizer.session_stopped.connect(stop_cb)\n",
    "    speech_recognizer.canceled.connect(stop_cb)\n",
    "    \n",
    "    speech_recognizer.start_continuous_recognition()\n",
    "    transcription = \" \".join(all_results)\n",
    "    return transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcription.txt\", \"w\") as fp:\n",
    "    fp.write(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"transcription.txt\", \"r\") as fp:\n",
    "    transcription = fp.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" So now, now what is the problem with the few short prompting, right? We just discussed right now that few short prompting we might be able to achieve a lot of things. But when there is a multi step reasoning that is required, right? We just prompting it by saying, OK, so here is a question, here is the answer. Now I'll give you the question. You do the task. OK. That's what few short prompting kind of you know, let's believe it right now. This does not work when the reasoning that is required requires multiple steps, right? So now you're just saying, OK, give some explanation and then just saying answer is 11 between this question to this answer, there are so many steps and thoughts that are required. To generate this right. So now can we explicitly get the model to generate those thoughts and then answer the question rather than trying to jump to, you know, some number based on the context that is provided by the question, right. That's the key idea behind. This one chain of thought. Method right? So like this motivation is clear, right? Because when there are there is not enough information in the problem. There is enough information for reasoning and solving this problem that has to like you know, the multiple steps will go on in our head to come up with this answer. But it is not a language modelling task. You have to understand the difference. What is the LLM trying to do? It sees the series of tokens and trying to. The next token there is no logic that is implemented as part of that. It is like just influenced by the previous set of tokens. What tokens have higher probability and then just gets generated. But can we induce that logical step by step thinking as part of the, you know, prompting technique itself? To get LLM to use the strategy for a new problem. So the multi step reasoning tasks need thinking through intermediate steps, right? So now can we induce LLMS to do that? Yes, because LLMS that have been like, you know, 10s of billions of parameters and higher have the ability to, you know, learn from your. Examples to kind of mimic the process of thinking, not just generating the answers, right. So this was published in this paper, The chain of thought prompting. I think this is one of the most influential prompting techniques. Right, And almost everything else after this, we'll pretty much use this idea. OK, so let's look at the method. So goal is to endow language models with ability to generate chain of thought. OK, and implementation. Again, we are using the same few short prompting. You have to start looking at the subtle differences in the prompt and what we are trying to do. It's all there in the way the examples are given. It's not there in the structure if the information is there in the way examples are given. The way the demonstrations are done and the power of elements is to understand those example demonstrations and try to mimic the process when a new input is given. OK. Let me before we go to the example, let me show this, OK? So if you notice here the key. Difference. OK, this is your standard prompting, right? Where you're still giving, you know, one shot example here and then asking the question. The answer that is generated is wrong here. By the way, if you give the same thing today, it will answer correctly. OK, so this is when the public paper was published or whichever model that they used. For this, but let's focus on the idea, right? So now this blue piece of information that is added into your exemplar, which is. The one shot example that you're giving for the problem, this one thing is a prompt. So here if you see, Roger started with five balls, 2 cans of three tennis balls, each is 6 tennis balls. So 5 + 6 = 11. So we're kind of showing the steps. As part of the demonstration itself, instead of just trying to answer. So it's. More detailed, more specific information that we are illustrating that do this kind of a thing and answer the question then just trying to generate the answer. OK, So what LLM then does is given this question, look at the output now that green piece is the chain of thought it is generated. By learning from one example that was given here. OK. And since LLM spends time generating this information OK, and that information broken down like which may be implicitly available in the problem statement, all that gets more explicitly made available as part of the context. Purely by using verbal reasoning, the answer that is generated can be. Much better and much more accurate than trying to do that. From the original, original, you know, problem and directly trying to guess that. OK, so it's almost like don't guess the answer, but follow some steps to break down the information and the chain of thought. How will you go about doing this and then generate those steps as well as the answer, OK, this helps the LLM to focus on the right kind of information. And the right. In the problem and then generate the answer. So the context that it gets is much much better right for answering the question than the original question is. Is this clear? So not the like the the detailed prompts. I mean it's not like they're just using one example. Like I think more examples are used as part of the prompting for the sake of brevity in presentation. They're just showing one example. So if you look at the paper, you can see more detailed prompts in the end, OK, but the idea remains just the same, right? So. We are inducing a particular style of thinking. By giving examples of that style of thinking. OK, so as such it is just a few short example, but the way we are structuring the examples and demonstrations is where we have control. It's almost like we are using. Solved problems. Kind of a context we are giving to the model and kind of encouraging it to use similar kind of thinking to solve any new problem given. OK. So there are, you know, more examples here, right? How the model kind of breaks down? For different types of problems, how the question information and the question is broken down into your chain of thought and answer is provided. So you might be finally interested only in the answer, right? So you have the option of inserting OK, you don't have to follow the exact same pattern. Right. You could, you know, model this thing one second, I'll just create one place where. OK. So you can say for in your demonstrations.  Oh, so you know that part. So we'll have like you can say question. No, this is bye. OK, you can use this question and give something you can say reasoning. And then you can provide something and then you can say answer. Is this right? You could break that down explicitly also, which is what will be done by the later prompts, but the idea is still the same, right? So. But this will help you separate the reasoning and answer maybe for your parsing stages later. Or you want to take the reasoning and maybe you want to use that reasoning and use the external tool to solve the problem and fill it in here. So this kind of this kind of adding these additional scaffoldings can give you a little more control. But the idea is the way we want the model to think, we can induce that thinking by just giving examples through future. Prompting, right? So what are some important advantages here? You can help us decompose the problem complex problem into intermediate steps, allowing more information processing, you know, for the LLM to generate reliable responses. So interpretability if you want to use the reasoning that is generated to give it to the end user or use it in some other way. In order to understand the model behaviour of why this answer was suggested, you could use the same technique. OK, so useful for, you know, math problems or reasoning where multi step reasonings is involved, right. So it's not just I can I can't read, I can't read the answer from the question directly. I need to do a few steps before answering there you can use chain of thought prompting. OK, and it's easy to elicit in LL Mississippi. This kind of a behaviour using few short part. So any questions about? Chain of thought because this is going to be a very crucial technique that you'll have to keep in mind. Many of them will build on top of this.\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transcription"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"For a given transcription from a video to be published online, give a very short pre-read for the viewers on what to expect from the video\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\nPREREAD:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this video, we explore the concept of \"chain of thought\" prompting in language models, focusing on its importance for multi-step reasoning tasks. You\\'ll learn how traditional prompting methods can fall short when complex reasoning is required, and how the chain of thought technique can help induce logical thinking in language models. We\\'ll discuss the method\\'s implementation, including examples that illustrate how to structure prompts effectively to improve the accuracy of model responses. Join us as we unpack this influential prompting technique and its applications in enhancing language model performance!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"For a given transcription from the video published online, give a summary of the video for the viewers\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\SUMMARY:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this video, the speaker discusses the concept of \"chain of thought prompting\" as a technique to enhance the performance of language models, particularly in tasks that require multi-step reasoning. They explain that while traditional few-shot prompting may work for straightforward queries, it often falls short when complex reasoning is needed. The key idea is to encourage models to articulate their thought processes step-by-step rather than jumping directly to answers.\\n\\nThe speaker highlights the importance of structuring prompts in a way that illustrates the reasoning process, thereby enabling the model to generate more accurate responses. By providing detailed examples that break down the problem into intermediate steps, the model can learn to mimic this logical thinking in its future outputs.\\n\\nThe video emphasizes that this approach not only improves the accuracy of answers but also enhances interpretability, allowing users to understand the reasoning behind the model\\'s conclusions. The speaker encourages viewers to adopt this technique for tasks involving complex reasoning, particularly in math problems, and suggests that chain of thought prompting is a foundational method that many subsequent techniques will build upon.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are an expert teacher in AI. For a given transcription from a video, generate 10 multiple choice questions that cover the topics discussed in this session. The questions are to be of recall-from-content type\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\QUESTIONS:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. What is the main problem with few-shot prompting when it comes to multi-step reasoning?\n",
      "   - A) It generates too many answers\n",
      "   - B) It does not effectively guide the model through the necessary reasoning steps\n",
      "   - C) It requires too much data\n",
      "   - D) It is not applicable to language models\n",
      "   \n",
      "2. What is the key idea behind the chain of thought prompting method?\n",
      "   - A) To provide straightforward answers without reasoning\n",
      "   - B) To induce logical, step-by-step thinking in the model\n",
      "   - C) To simplify the input questions\n",
      "   - D) To minimize the number of examples used in prompting\n",
      "\n",
      "3. How does a language model like LLM generate tokens?\n",
      "   - A) By implementing logical reasoning\n",
      "   - B) Based on a series of previous tokens and their probabilities\n",
      "   - C) Through external computational tools\n",
      "   - D) By guessing the answers\n",
      "\n",
      "4. What does the implementation of chain of thought prompting aim to achieve?\n",
      "   - A) Generate random outputs\n",
      "   - B) Enable language models to generate a series of logical steps before arriving at an answer\n",
      "   - C) Eliminate the need for examples\n",
      "   - D) Increase the complexity of the model's architecture\n",
      "\n",
      "5. According to the transcription, what is a significant advantage of using chain of thought prompting?\n",
      "   - A) It reduces computation time\n",
      "   - B) It allows complex problems to be broken down into intermediate steps\n",
      "   - C) It avoids the use of examples altogether\n",
      "   - D) It results in faster training of language models\n",
      "\n",
      "6. In the example provided in the transcription, what was the result of using a standard prompting technique?\n",
      "   - A) The answer generated was correct\n",
      "   - B) The answer generated was wrong\n",
      "   - C) No answer was generated\n",
      "   - D) The model did not understand the question\n",
      "\n",
      "7. How can detailed prompts improve the performance of language models?\n",
      "   - A) By providing straightforward answers\n",
      "   - B) By encouraging the model to follow specific reasoning patterns\n",
      "   - C) By simplifying the input data\n",
      "   - D) By reducing the number of examples needed\n",
      "\n",
      "8. Which type of problems is chain of thought prompting particularly useful for?\n",
      "   - A) Simple factual queries\n",
      "   - B) Math problems or reasoning tasks that require multiple steps\n",
      "   - C) Creative writing tasks\n",
      "   - D) Image recognition tasks\n",
      "\n",
      "9. What type of information does the model focus on when using chain of thought prompting?\n",
      "   - A) The final answer alone\n",
      "   - B) The reasoning process and intermediate steps involved in reaching the answer\n",
      "   - C) The length of the input question\n",
      "   - D) The number of examples provided\n",
      "\n",
      "10. What does the presenter suggest about the model's ability to learn from examples?\n",
      "    - A) It cannot learn from examples at all\n",
      "    - B) It can mimic the process of thinking from given examples\n",
      "    - C) It only learns from incorrect examples\n",
      "    - D) It relies solely on its initial training data without learning from new examples\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manual-script-videos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
