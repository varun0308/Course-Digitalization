{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "from utils import save_audio_from_mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 139M/139M [00:08<00:00, 17.7MiB/s]\n"
     ]
    }
   ],
   "source": [
    "model = whisper.load_model(\"base.en\")      # turbo is recommended in sample code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'audio.mp3'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save_audio_from_mp4(\"Ses 03.mp4\", audio_file=\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(\"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcription = result['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "model = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"For a given transcription from a video to be published online, give a very short pre-read for the viewers on what to expect from the video\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\nPREREAD:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"In this video, we'll explore the concept of chain of thought prompting in language models, a technique that enhances their ability to perform multi-step reasoning tasks. You'll learn why traditional few-shot prompting might fall short in complex problem-solving scenarios, and how structured examples can guide models to generate more accurate answers by breaking down the reasoning process. Join us as we delve into the nuances of prompting strategies and their implications for improving language model performance!\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"For a given transcription from the video published online, give a summary of the video for the viewers\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\nSUMMARY:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In this video, the speaker discusses the concept of \"chain of thought prompting\" in large language models (LLMs). They explain that while few-shot prompting can be effective for certain tasks, it struggles with multi-step reasoning problems. The key idea is to encourage LLMs to generate intermediate thoughts rather than jumping directly to an answer. By providing detailed examples that illustrate the reasoning process, LLMs can learn to mimic this thinking style, leading to more accurate responses. The speaker emphasizes that the structure of the examples is crucial in guiding the model\\'s thought process. They highlight the advantages of this method for solving complex problems, improving interpretability, and fostering reliable answers, especially in situations requiring intricate reasoning. The discussion underlines the significance of chain of thought prompting as a foundational technique in the realm of LLMs.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"\"\"You are an expert teacher in AI. For a given transcription from a video, section the content into 'Introduction', 'Learning objectives(if applicable)', 'Learning content', 'Challenges/Common mistakes(if applicable)', 'Conclusion'\n",
    "\n",
    "Constraints:\n",
    "- Do not alter the transcription given. Only put them into their relevant section\"\"\"),\n",
    "    HumanMessage(content=f\"TRANSCRIPTION: {transcription}\\nSECTIONED CONTENT:\"),\n",
    "]\n",
    "\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Introduction:**  \n",
      "So, now, now what is the problem with few short prompting right? We just discussed right now that few short prompting we might be able to achieve lot of things. But when there is a multi step reasoning that is required right, we just prompting it by saying ok. So, here is a question here is answer. Now, I will give you the question you do the task ok. That is what few short prompting kind of you know let us you believe right. Now, this does not work when the reasoning that is required requires multiple steps right.\n",
      "\n",
      "**Learning Content:**  \n",
      "So, now you are just saying ok give some explanation and then just saying answer is 11 between this question to this answer there are so many steps and thoughts that are required to generate this right. So, now can we explicitly get the model to generate those thoughts and then answer the question rather than trying to jump to you know some number based on the context that is provided by the question right. That is the key idea behind this one chain of thought right right. So, like this motivation is clear right because when there are there is not enough information in the problem there is enough information for reasoning and solving this problem that has to like you know the multiple steps will go on in our head to come up with this answer. But it is not a language modeling task you have to understand the difference what is the LLM trying to do it sees the series of tokens and trying to predict the next token there is no logic that is implemented as part of that it is like just influenced by the previous set of tokens what tokens have higher probability and then just gets generated. That can be induced that logical step by step thinking as part of the you know prompting technique itself to get LLM to use this strategy for a new problem. So, the multi step reasoning tasks need thinking through intermediate steps right. So, now can we induce LLM's to do that yes because LLM's that have been like you know tens of billions of parameters and higher have the ability to you know learn from your examples to kind of mimic the process of thinking not just generating the answers right. So, this was published in this paper the chain of thought prompting I think this is one of the most influential prompting techniques right and almost everything else after this will pretty much use this idea ok. So, let us look at the method. So, goal is to endo language models with ability to generate chain of thought ok and implementation again we are using the same flu shot prompting you will have to start looking at the subtle differences in the prompt and what we are trying to do it is all there in the way the examples are given it is not there in the structure if the information is there in the way examples are given the way the demonstrations are done and the power of LLM's is to understand those example demonstrations and try to mimic the process when new input is given ok. Let me before go with the example let me show this itself ok. So, if you notice here the key difference this is your standard prompting right where you are still giving you know one shot example here and then asking the question the answer that is generated is wrong here. By the way if you give the same thing today it will answer correctly ok. So, this is when the paper was published or whichever model that they used for this, but let us focus on the idea right. So, now this blue piece of information that is added into your example which is the one shot example that you are giving for the prompt this one thing is a prompt right. So, here if you see Rogers started with 5 balls 2 cans of 3 tennis balls each is 6 tennis balls. So, 5 plus 6 equals 11. So, we are kind of showing the steps as part of the demonstration itself instead of just trying to answer. So, it is a more detailed more specific information that we are illustrating that do this kind of a thing and answer the question then just trying to generate the answer ok. So, what LLM then does is given this question look at the output now that green piece is the chain of thought it is generated by learning from one example that was given here ok. And since LLM spends time generating this information ok and that information broken down like which may be implicitly available in the problem statement all that gets more explicitly made available as part of a context. Purely by using verbal reasoning the answer that is generated can be much better and much more accurate than trying to do that from the original original you know problem and directly trying to guess the answer ok. So, it is almost like do not guess the answer but follow some steps to break down the information and the chain of thought how will you go about doing this and then generate those steps as well as the answer ok. This helps the LLM to focus on the right kind of information and the right in the problem and then generate the answer. So, the context that it gets is much much better right for answering the question than the original question is this clear. So, note the like the the detailed prompts I mean it is not like they are just using one example like I think more examples are used as part of the prompting for the sake of brevity in presentation they just showing one example. So, if you look at the paper you can see more detailed prompts in the end up ok, but the idea remains just the same right. So, we are inducing a particular style of thinking by giving examples of that style of thinking ok. So, as such it is just a few short example, but the way we are structuring the examples and demonstrations is where we have control. It is almost like we are using solved problems kind of a context we are giving to the model and kind of encouraging it to use similar kind of thinking to solve any new problem given ok. So, there are you know more examples here right how the model kind of breaks down for different types of problems how the question information on the question is broken down into your chain of thought and the answer is provided. So, you might be finally interested only in the answer right. So, you have the option of inserting ok you do not have to follow the exact same pattern right you could you know model this thing one second object let us create one place where ok. So, you can say for in your demonstrations with all these features. So, you know the part so, you know like you can say question oh no this is right ok. You can use this question and give something you can say reasoning and then you can provide something and then you can say answer is this right. You could break that down explicitly also which is what will be done by very later to prompts, but the idea is still the same right. So, but this will help you separate the reasoning and answer maybe for your passing stages later or you want to take the reasoning and maybe you want to use that reasoning and use the external tool to solve the problem and fill it in here. So, this kind of this kind of adding these additional scaffoldings can give you little more control, but the idea is the way we want the model to think we can induce that thinking by just giving examples through few short prompting right.\n",
      "\n",
      "**Challenges/Common Mistakes:**  \n",
      "So, what are some important advantages here? You can help us decompose the problem complex problem into intermediate steps allowing more information processing you know for the LLM to generate reliable responses. So, interpretability if you want to use the reasoning that is generated to give it to the end user or use it in some other way in order to understand the model behavior or why this answer was suggestive you could use the same technique. So, useful for you know math problems or reasoning where multi-step reasonings is involved right. So, it is not just I can I cannot read I cannot read the answer from the question directly I need to do few steps before answering there you can use chain of thought prompting and it is easy to elicit in LLM's the this kind of a behavior using few short part. So, any questions about chain of thought because this is going to be a very crucial technique that you will have to keep in mind many of them will build on top of this.\n",
      "\n",
      "**Conclusion:**  \n",
      "This helps the LLM to focus on the right kind of information and the right in the problem and then generate the answer. So, the context that it gets is much much better right for answering the question than the original question is this clear.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"\"\"You are an expert teacher in AI. For a given CONTENT from a video, generate 3 multiple choice questions from each section to recall from the content of the video to keep the users engaged\n",
    "                  \n",
    "Constrains:\n",
    "- These sections are not visible to the user. Hence do not include these terms in the questions\"\"\"),\n",
    "    HumanMessage(content=f\"CONTENT: {response.content}\\nQUESTIONS:\"),\n",
    "]\n",
    "response = model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Introduction Questions:**\n",
      "\n",
      "1. What is the primary limitation associated with few-shot prompting?\n",
      "   - A) It requires too much data.\n",
      "   - B) It struggles with multi-step reasoning.\n",
      "   - C) It is too complex for models.\n",
      "   - D) It generates irrelevant answers.\n",
      "\n",
      "2. What is deemed essential for tasks that involve several steps?\n",
      "   - A) Direct answers without explanations.\n",
      "   - B) A single prompt example.\n",
      "   - C) Detailed reasoning and thought processes.\n",
      "   - D) Visual aids to assist understanding.\n",
      "\n",
      "3. What belief does few-shot prompting foster among users regarding its capabilities?\n",
      "   - A) Instantaneous results with no effort.\n",
      "   - B) Simplified answers to complex questions.\n",
      "   - C) Effective reasoning in multi-step problems.\n",
      "   - D) Accurate predictions based on a single instance.\n",
      "\n",
      "---\n",
      "\n",
      "**Learning Content Questions:**\n",
      "\n",
      "1. What is the aim of the \"chain of thought\" approach in language models?\n",
      "   - A) To skip reasoning steps for faster answers.\n",
      "   - B) To explicitly generate reasoning steps before arriving at an answer.\n",
      "   - C) To provide answers with no context.\n",
      "   - D) To focus solely on numerical outputs.\n",
      "\n",
      "2. How do large language models (LLMs) learn to simulate thinking processes?\n",
      "   - A) By memorizing past examples.\n",
      "   - B) By using complex algorithms to predict answers.\n",
      "   - C) By learning from examples and generating intermediate reasoning.\n",
      "   - D) By ignoring previous tokens in prompts.\n",
      "\n",
      "3. What is crucial for generating better answers in the context of chain of thought prompting?\n",
      "   - A) Guessing based on intuition.\n",
      "   - B) Providing detailed prompts and examples.\n",
      "   - C) Simplifying the problem to one step.\n",
      "   - D) Focusing on irrelevant details.\n",
      "\n",
      "---\n",
      "\n",
      "**Challenges/Common Mistakes Questions:**\n",
      "\n",
      "1. What is a key advantage of employing chain of thought prompting for intricate problems?\n",
      "   - A) It eliminates the need for reasoning.\n",
      "   - B) It allows for quick responses without detailed processing.\n",
      "   - C) It helps decompose problems into intermediate steps for better information processing.\n",
      "   - D) It requires less computational power.\n",
      "\n",
      "2. How can reasoning generated by large language models be effectively utilized?\n",
      "   - A) To confuse the end users.\n",
      "   - B) To avoid explaining the model's behavior.\n",
      "   - C) To provide insights into the model's behavior and answer accuracy.\n",
      "   - D) To disregard the generated reasoning altogether.\n",
      "\n",
      "3. For which type of problems is chain of thought prompting especially beneficial?\n",
      "   - A) Simple yes/no questions.\n",
      "   - B) Problems requiring multi-step reasoning.\n",
      "   - C) Problems with straightforward answers.\n",
      "   - D) Problems that can be solved in one step.\n",
      "\n",
      "---\n",
      "\n",
      "**Conclusion Questions:**\n",
      "\n",
      "1. What does the conclusion highlight about the context provided to language models?\n",
      "   - A) It is less useful than the original question.\n",
      "   - B) It is crucial for generating accurate answers.\n",
      "   - C) It complicates the answering process.\n",
      "   - D) It is irrelevant to the problem-solving process.\n",
      "\n",
      "2. In what way does chain of thought prompting improve the answering process?\n",
      "   - A) By providing vague information.\n",
      "   - B) By focusing the model on the right kind of information.\n",
      "   - C) By encouraging random guessing.\n",
      "   - D) By eliminating the need for reasoning.\n",
      "\n",
      "3. What is the primary objective of using chain of thought prompting as discussed in the conclusion?\n",
      "   - A) To generate faster answers without context.\n",
      "   - B) To enhance the reasoning process of LLMs for better outcomes.\n",
      "   - C) To limit the amount of information processed.\n",
      "   - D) To simplify the prompting technique.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "manual-script-videos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
